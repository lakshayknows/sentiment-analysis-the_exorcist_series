<img width="1148" height="691" alt="image" src="https://github.com/user-attachments/assets/c657a17c-5e41-4948-a551-ca4abba3a44b" /><img width="1148" height="691" alt="image" src="https://github.com/user-attachments/assets/0297cf11-2d36-4fa8-9996-b1e88a9625b2" />ğŸ¬ Sentiment Analysis of The Exorcist Series Reviews

TL;DR: An end-to-end NLP pipeline analyzing Rotten Tomatoes reviews of The Exorcist. Built with LangChain + Hugging Face to compare prompt strategies (direct vs. role-playing), showcasing how prompting affects model reliability.

ğŸ–¼ï¸ Project Workflow


(see docs/NLP Analysis of _The Exorcist_ Series Reviews.pdf
 for full detail)

ğŸ“‚ Repository Structure
.
â”œâ”€â”€ preprocessing/                     # Notebooks for scraping & cleaning
â”œâ”€â”€ src/                               # Core Python scripts
â”œâ”€â”€ templates/                         # Prompt templates
â”œâ”€â”€ data/                              # Final dataset
â”œâ”€â”€ docs/                              # Visuals & reports
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ LICENSE

ğŸ•¸ï¸ Data Collection & Preprocessing

Notebooks inside preprocessing/
:

web-scraping-movie-reviews.ipynb â†’ Scrapes The Exorcist reviews from Rotten Tomatoes.

sentiment-analysis-of-the-exorcist-reviews.ipynb â†’ Cleans and preprocesses the raw text (lowercasing, stopwords, punctuation, tokenization, lemmatization).

Final output: data/processed_data.csv

âš™ï¸ Workflow

Scraping â†’ Collect reviews from Rotten Tomatoes.

Preprocessing â†’ Clean & normalize text.

Prompt Engineering â†’ Two strategies:

Direct prompt (concise).

Role-playing prompt (persona-based).

Model Interaction â†’ Hugging Face LLM: meta-llama/Llama-3.1-8B-Instruct.

Evaluation & Troubleshooting â†’ Compare outputs, document errors, assess hallucinations.

ğŸ’» Example Code
Preprocessing (src/data.py)
from nltk.tokenize import word_tokenize
from nltk.stem import WordNetLemmatizer
import re

def clean_text(text):
    text = re.sub(r"http\S+|www\S+", "", text)   # remove URLs
    tokens = word_tokenize(text.lower())         # lowercase + tokenize
    lemmatizer = WordNetLemmatizer()
    cleaned = [lemmatizer.lemmatize(t) for t in tokens if t.isalpha()]
    return " ".join(cleaned)

Sentiment Inference (src/app.py)
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain
import json

# Load prompt
with open("templates/template_1.json") as f:
    prompt_dict = json.load(f)
prompt = PromptTemplate(**prompt_dict)

# Run LLM chain
chain = LLMChain(llm=hf_llm, prompt=prompt)
review_text = "brings,back,,original,horror,,73"
response = chain.run({"input": review_text})

print("Sentiment result:", response)

ğŸ“Š Example Output

Sample Review:

"brings,back,,original,horror,,73"


Direct Prompt âœ…

Sentiment: POSITIVE
Reason: Nostalgic reference to â€œoriginal horrorâ€ implies enthusiasm.


Role-Playing Prompt âŒ

Sentiment: NEGATIVE
Reason: Over-interpreted punctuation â†’ hallucinated disappointment.


ğŸ‘‰ Demonstrates how prompt design directly impacts LLM reliability.

ğŸš€ How to Run
git clone https://github.com/lakshayknows/sentiment-analysis-the_exorcist_series.git
cd sentiment-analysis-the_exorcist_series
python -m venv venv
source venv/bin/activate   # On Windows: venv\Scripts\activate
pip install -r requirements.txt


Add Hugging Face API token in .env:

HUGGINGFACEHUB_API_TOKEN="hf_xxxxxxxxxxxxxxxxxxxx"


Run:

python src/app.py

ğŸ› ï¸ Tools & Libraries

Python

pandas, NLTK, TextBlob â†’ preprocessing

LangChain â†’ prompt orchestration

Hugging Face Hub â†’ meta-llama LLM

Napkin.ai â†’ flowchart design

ğŸ¯ Key Takeaways

Direct prompts â†’ stable results

Persona prompts â†’ risk of hallucinations

Preprocessing + prompt strategy â†’ better reliability

ğŸ“œ License

Licensed under the MIT License
.

âœ¨ From raw web-scraped chaos to model-guided clarity â€” an exorcism of noisy data into sentiment truth. ğŸ‘»
