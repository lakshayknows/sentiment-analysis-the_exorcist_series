ğŸ¬ Sentiment Analysis of The Exorcist Series Reviews

TL;DR: An end-to-end NLP pipeline analyzing Rotten Tomatoes reviews of The Exorcist. Built with LangChain + Hugging Face to compare prompt strategies (direct, role-playing, and few-shot), showcasing how prompting affects model reliability.

ğŸ–¼ï¸ Project Workflow


(see docs/NLP Analysis of _The Exorcist_ Series Reviews.pdf
 for full detail)

ğŸ“‚ Repository Structure
.
â”œâ”€â”€ preprocessing/                     # Notebooks for scraping & cleaning
â”‚   â”œâ”€â”€ web-scraping-movie-reviews.ipynb
â”‚   â””â”€â”€ sentiment-analysis-of-the-exorcist-reviews.ipynb
â”‚
â”œâ”€â”€ src/                               # Core Python scripts
â”‚   â”œâ”€â”€ app.py
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ data.py
â”‚   â””â”€â”€ create_template.py
â”‚
â”œâ”€â”€ templates/                         # Prompt templates
â”‚   â”œâ”€â”€ template_1.json   # Direct
â”‚   â”œâ”€â”€ template_2.json   # Role-playing
â”‚   â””â”€â”€ template_3.json   # Few-shot
â”‚
â”œâ”€â”€ data/                              # Final dataset
â”‚   â””â”€â”€ processed_data.csv
â”‚
â”œâ”€â”€ docs/                              # Visuals & reports
â”‚   â”œâ”€â”€ NLP Analysis of _The Exorcist_ Series Reviews.pdf
â”‚   â””â”€â”€ flowchart.png
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ LICENSE

ğŸ•¸ï¸ Data Collection & Preprocessing

Notebooks inside preprocessing/
:

web-scraping-movie-reviews.ipynb â†’ Scrapes The Exorcist reviews from Rotten Tomatoes.

sentiment-analysis-of-the-exorcist-reviews.ipynb â†’ Cleans and preprocesses the raw text (lowercasing, stopwords, punctuation, tokenization, lemmatization).

Final output: data/processed_data.csv

âš™ï¸ Workflow

Scraping â†’ Collect reviews from Rotten Tomatoes.

Preprocessing â†’ Clean & normalize text.

Prompt Engineering â†’ Three strategies:

Direct prompt (concise).

Role-playing prompt (persona-based).

Few-shot prompt (anchored with labeled examples).

Model Interaction â†’ Hugging Face LLM: meta-llama/Llama-3.1-8B-Instruct.

Evaluation & Troubleshooting â†’ Compare outputs, document errors, assess hallucinations.

ğŸ’» Example Code
Preprocessing (src/data.py)
import pandas as pd
def load_data():
    data = pd.read_csv("data/processed_data.csv")
    return data

Sentiment Inference (src/main.py)
from langchain_huggingface import ChatHuggingFace, HuggingFaceEndpoint
from dotenv import load_dotenv
from data import load_data
from langchain_core.prompts import load_prompt

# Load data and environment variables
load_dotenv()
data = load_data()

# Model from Hugging Face
llm = HuggingFaceEndpoint(
    repo_id="meta-llama/Llama-3.1-8B-Instruct",
    task="text-generation"
)
model = ChatHuggingFace(llm=llm)

# Load prompt templates
prompt1 = load_prompt('templates/template_1.json')
prompt2 = load_prompt('templates/template_2.json')
prompt3 = load_prompt('templates/template_3.json')

sample_review = data['flat_reviews'].iloc[0]

print(f"Review: '{sample_review}'")
print("-" * 40)

# Direct Prompt
chain1 = prompt1 | model
result1 = chain1.invoke({"review_text": sample_review})
print("\nResult from Prompt 1 (Direct):")
print(result1.content)

# Role-Playing Prompt
chain2 = prompt2 | model
result2 = chain2.invoke({"review_text": sample_review})
print("\nResult from Prompt 2 (Role-Playing):")
print(result2.content)

# Few-Shot Prompt
chain3 = prompt3 | model
result3 = chain3.invoke({"review_text": sample_review})
print("\nResult from Prompt 3 (Few-Shot):")
print(result3.content)

ğŸ“Š Example Output

Sample Review:

"brings,back,,original,horror,,73"


Direct Prompt âœ…

Sentiment: POSITIVE
Reason: Nostalgic reference to â€œoriginal horrorâ€ implies enthusiasm.


Role-Playing Prompt âŒ

Sentiment: NEGATIVE
Reason: Over-interpreted punctuation â†’ hallucinated disappointment.


Few-Shot Prompt âœ…

Sentiment: POSITIVE
Reason: Anchored by examples, the model avoids over-interpretation and classifies correctly.


ğŸ‘‰ Demonstrates how prompt design directly impacts LLM reliability.

ğŸš€ How to Run
git clone https://github.com/lakshayknows/sentiment-analysis-the_exorcist_series.git
cd sentiment-analysis-the_exorcist_series
python -m venv venv
source venv/bin/activate   # On Windows: venv\Scripts\activate
pip install -r requirements.txt


Add Hugging Face API token in .env:

HUGGINGFACEHUB_API_TOKEN="hf_xxxxxxxxxxxxxxxxxxxx"


Run:

python src/main.py

ğŸ› ï¸ Tools & Libraries

Python

pandas, NLTK, TextBlob â†’ preprocessing

LangChain â†’ prompt orchestration

Hugging Face Hub â†’ meta-llama LLM

Napkin.ai â†’ flowchart design

ğŸ¯ Key Takeaways

Direct prompts â†’ stable results

Persona prompts â†’ risk of hallucinations

Few-shot prompts â†’ reduce hallucinations, improve reliability

Preprocessing + prompt strategy â†’ robust sentiment classification

ğŸ“œ License

Licensed under the MIT License
.

âœ¨ From raw web-scraped chaos to model-guided clarity â€” an exorcism of noisy data into sentiment truth. ğŸ‘»
